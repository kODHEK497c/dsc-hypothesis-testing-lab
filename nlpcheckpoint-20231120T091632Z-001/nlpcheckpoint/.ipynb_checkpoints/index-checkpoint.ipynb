{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee3b0c2c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "35459ba3e08fc82dfd66bf081ab5eb9b",
     "grade": false,
     "grade_id": "cell-34139fb74befcf21",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Natural Language Processing Checkpoint\n",
    "This checkpoint is designed to test your understanding of the content from the Text Classification Cumulative Lab. \n",
    "\n",
    "Specifically, this will cover:\n",
    "\n",
    "- Preprocessing and exploring text data using `nltk`\n",
    "- Vectorizing text data using a bag-of-words approach\n",
    "- Fitting machine learning models using vectorized text data\n",
    "\n",
    "### Data Understanding\n",
    "\n",
    "In this repository under the file path `/movie_descriptions.csv` there is a CSV file containing the titles, genres, and descriptions for 5,000 films pulled from [IMDb](https://www.kaggle.com/hijest/genre-classification-dataset-imdb).\n",
    "\n",
    "**The features of interest for this analysis will be:**\n",
    "\n",
    "1. `desc`: The description of the film, which we will explore and then use as the features of our model\n",
    "2. `genre`: The target for our predictive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfa0d304",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T18:51:16.295737Z",
     "start_time": "2021-11-08T18:51:15.844207Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5df654015de6a049f80ed090e5a2cc5e",
     "grade": false,
     "grade_id": "cell-281bb10d1f157ca2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>31370</td>\n",
       "      <td>Do You Believe? (2007)</td>\n",
       "      <td>documentary</td>\n",
       "      <td>Do you believe?\" digs deep into our spiritual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2507</th>\n",
       "      <td>25529</td>\n",
       "      <td>The House That Jack Broke (2013)</td>\n",
       "      <td>drama</td>\n",
       "      <td>Early one morning, two FBI agents, Portman an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2376</th>\n",
       "      <td>5405</td>\n",
       "      <td>Children of Peace (2016)</td>\n",
       "      <td>documentary</td>\n",
       "      <td>The Bosnian War was an international armed co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>49949</td>\n",
       "      <td>Hwioribaram (2009)</td>\n",
       "      <td>drama</td>\n",
       "      <td>During winter vacation of their sophomore yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>21445</td>\n",
       "      <td>Gui pian wang zhi zai xian xiong bang (1999)</td>\n",
       "      <td>horror</td>\n",
       "      <td>At a Hong Kong dormitory, the cook's little g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           title          genre  \\\n",
       "789   31370                         Do You Believe? (2007)    documentary    \n",
       "2507  25529               The House That Jack Broke (2013)          drama    \n",
       "2376   5405                       Children of Peace (2016)    documentary    \n",
       "1378  49949                             Hwioribaram (2009)          drama    \n",
       "598   21445   Gui pian wang zhi zai xian xiong bang (1999)         horror    \n",
       "\n",
       "                                                   desc  \n",
       "789    Do you believe?\" digs deep into our spiritual...  \n",
       "2507   Early one morning, two FBI agents, Portman an...  \n",
       "2376   The Bosnian War was an international armed co...  \n",
       "1378   During winter vacation of their sophomore yea...  \n",
       "598    At a Hong Kong dormitory, the cook's little g...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "import pandas as pd\n",
    "\n",
    "# Import the data\n",
    "data = pd.read_csv('movie_descriptions.csv')\n",
    "\n",
    "# Output a sample\n",
    "data = data.sample(1500, random_state=100)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b0e650",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b6b450810c99a898425797ced0225fc",
     "grade": false,
     "grade_id": "cell-f04cd94df7c7b107",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "data.genre.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902c604c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef1abb552562e7d9144e06355ce4d382",
     "grade": false,
     "grade_id": "cell-402a4b03e41919f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Requirements\n",
    "\n",
    "1. Initialize tokenizer and stemmer objects to prepare for text preprocessing\n",
    "2. Write a function that implements standard \"bag of words\" text preprocessing\n",
    "3. Initialize and fit a `CountVectorizer` from `sklearn`\n",
    "3. Vectorize data using `CountVectorizer`\n",
    "4. Fit a decision tree classifier on vectorized text data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87ec775",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b31915b1e616c339bab1ea801ce5e1e",
     "grade": false,
     "grade_id": "cell-f86b392a061c5b2e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1) Initialize Tokenizer, Stemmer, and Stopwords Objects\n",
    "\n",
    "In our exploratory text analysis, we will:\n",
    "\n",
    "* Standardize case\n",
    "* Tokenize (split text into words)\n",
    "* Remove stopwords\n",
    "* Stem words\n",
    "\n",
    "Three of those steps require that we import some functionality from `nltk`. In the cell below, create:\n",
    "\n",
    "* An instance of `RegexpTokenizer` ([documentation here](https://www.nltk.org/api/nltk.tokenize.regexp.html#module-nltk.tokenize.regexp)) called `tokenizer`\n",
    "  * The regex pattern should select all words with three or more characters. You can use the pattern `r\"(?u)\\w{3,}\"`\n",
    "* A list of stopwords (documentation [here](https://www.nltk.org/api/nltk.corpus.html#module-nltk.corpus) and [here](https://www.nltk.org/nltk_data/)) called `stopwords_list`\n",
    "* An instance of `PorterStemmer` ([documentation here](https://www.nltk.org/api/nltk.stem.porter.html)) called `stemmer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc89f75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T18:51:17.616392Z",
     "start_time": "2021-11-08T18:51:16.358327Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "891e78118775e9e6aacc4849c4acb705",
     "grade": false,
     "grade_id": "cell-ac8d9d14c1329b01",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this line in a new cell if nltk isn't working\n",
    "# !pip install nltk\n",
    "\n",
    "# Replace None with appropriate code\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Create an intance of the RegexpTokenizer with the variable name `tokenizer`\n",
    "# The regex pattern should select all words with three or more characters\n",
    "tokenizer = None\n",
    "\n",
    "# Create a list of stopwords in English\n",
    "stopwords_list = None\n",
    "\n",
    "# Create an instance of nltk's PorterStemmer with the variable name `stemmer`\n",
    "stemmer = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7c188a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T18:51:17.629501Z",
     "start_time": "2021-11-08T18:51:17.618915Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f88ce46541d94f58ce0176fcd373b4b",
     "grade": true,
     "grade_id": "cell-a27b368402c28604",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Checking that variables are no longer None\n",
    "assert tokenizer\n",
    "assert stopwords_list\n",
    "assert stemmer\n",
    "\n",
    "# PUT ALL WORK FOR THE ABOVE QUESTION ABOVE THIS CELL\n",
    "# THIS UNALTERABLE CELL CONTAINS HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389377a6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb6d14b462bc229e1494d59222496295",
     "grade": false,
     "grade_id": "cell-33101c1955e971d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2) Write a Function That Implements Standard Text Preprocessing\n",
    "\n",
    "In the cell below, complete the `preprocess_text` function so the inputted text is returned lower cased, tokenized, stopwords removed, and stemmed.\n",
    "\n",
    "For example, if you input the text\n",
    "\n",
    "```\n",
    "This is an example sentence for preprocessing.\n",
    "```\n",
    "\n",
    "The result of `preprocess_text` should be this list of strings:\n",
    "\n",
    "```python\n",
    "['exampl', 'sentenc', 'preprocess']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772bda95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T18:51:17.635823Z",
     "start_time": "2021-11-08T18:51:17.632236Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fb4d3f4a59b17819cd3ea4eb49af4f6",
     "grade": false,
     "grade_id": "cell-614bf94825adaa14",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text, tokenizer, stopwords_list, stemmer):\n",
    "    # Standardize case (lowercase the text)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Tokenize text using `tokenizer`\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Remove stopwords using `stopwords_list`\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Stem the tokenized text using `stemmer`\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Return the preprocessed text\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "preprocess_text(\"This is an example sentence for preprocessing.\", tokenizer, stopwords_list, stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307348f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T18:51:17.654363Z",
     "start_time": "2021-11-08T18:51:17.638116Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "765370efd3880073f7829c8fba3b32f1",
     "grade": true,
     "grade_id": "cell-0eb9dc55a34b86bf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from types import FunctionType\n",
    "\n",
    "assert type(preprocess_text) == FunctionType\n",
    "assert type(preprocess_text('Example text', tokenizer, stopwords_list, stemmer)) == list\n",
    "# PUT ALL WORK FOR THE ABOVE QUESTION ABOVE THIS CELL\n",
    "# THIS UNALTERABLE CELL CONTAINS HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72077659",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d44201f153b20be73abe5fc565aa8e91",
     "grade": false,
     "grade_id": "cell-0897c963ea268a17",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that the function has been created, use it to preprocess the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31225ecb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f9e0fe22d21bca15a6966ea07b81c45",
     "grade": false,
     "grade_id": "cell-5a65bd7ab76cef9a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "# (This may take a while due to nested loops)\n",
    "text_data = data.desc.apply(lambda x: preprocess_text(x, tokenizer, stopwords_list, stemmer))\n",
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644f78e9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b5fb51bdb1464b25c0428c03df59b8e",
     "grade": false,
     "grade_id": "cell-eea69e9c014d5d8a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "data[\"preprocessed_text\"] = text_data\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b9b970",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40350eb42c93073fcc6aaf4dc6f432aa",
     "grade": false,
     "grade_id": "cell-6055dd6b224b8099",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let's take a look at the top ten most frequent words for each genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300d157d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "99b70aecedbe26a7f7267c86483effd8",
     "grade": false,
     "grade_id": "cell-89aa21c97d821cb0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up figure and axes\n",
    "fig, axes = plt.subplots(nrows=7, figsize=(12, 12))\n",
    "\n",
    "# Empty dict to hold words that have already been plotted and their colors\n",
    "plotted_words_and_colors = {}\n",
    "# Establish color palette to pull from\n",
    "# (If you get an error message about popping from an empty list, increase this #)\n",
    "color_palette = sns.color_palette('cividis', n_colors=38)\n",
    "\n",
    "# Creating a plot for each unique genre\n",
    "data_by_genre = [y for _, y in data.groupby('genre', as_index=False)]\n",
    "for idx, genre_df in enumerate(data_by_genre):\n",
    "    # Find top 10 words in this genre\n",
    "    all_words_in_genre = genre_df.preprocessed_text.explode()\n",
    "    top_10 = all_words_in_genre.value_counts()[:10]\n",
    "    \n",
    "    # Select appropriate colors, reusing colors if words repeat\n",
    "    colors = []\n",
    "    for word in top_10.index:\n",
    "        if word not in plotted_words_and_colors:\n",
    "            new_color = color_palette.pop(0)\n",
    "            plotted_words_and_colors[word] = new_color\n",
    "        colors.append(plotted_words_and_colors[word])\n",
    "    \n",
    "    # Select axes, plot data, set title\n",
    "    ax = axes[idx]\n",
    "    ax.bar(top_10.index, top_10.values, color=colors)\n",
    "    ax.set_title(genre_df.iloc[0].genre.title())\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655871f8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a6f924f63f7d44bbc19ed580462b57d1",
     "grade": false,
     "grade_id": "cell-8b9cdaabf9fb047d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3) Fit a Count Vectorizer\n",
    "\n",
    "Now that we have explored the data some, let's prepare it for modeling.\n",
    "\n",
    "Before we fit a vectorizer to the data, we need to convert the list of tokens for each document back to a string datatype and create a train test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4070b70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T18:51:40.308407Z",
     "start_time": "2021-11-08T18:51:40.292643Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bbf12b884d8062f12f015107139d162f",
     "grade": false,
     "grade_id": "cell-b51f2230605c794d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert token lists to strings\n",
    "data[\"joined_preprocessed_text\"] = data[\"preprocessed_text\"].str.join(\" \")\n",
    "\n",
    "# Create train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[\"joined_preprocessed_text\"], data.genre, test_size=0.3, random_state=2021)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e817b5bd",
   "metadata": {},
   "source": [
    "**In the cell below, create a CountVectorizer instance ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)) with default arguments, called `vectorizer`, and fit it to the training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c49815",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T18:51:40.582899Z",
     "start_time": "2021-11-08T18:51:40.310715Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67d2e240ffaff39ab802f7586092578e",
     "grade": false,
     "grade_id": "cell-5f28c9cfadfcd688",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Import the CountVectorizer object from sklearn\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Create a `vectorizer` instance\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Fit the vectorizer to the training data\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e035024d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T18:51:40.807099Z",
     "start_time": "2021-11-08T18:51:40.585119Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "310b5e1d06c4d236fc118443eaf15669",
     "grade": true,
     "grade_id": "cell-27b308c317f85510",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert vectorizer\n",
    "# PUT ALL WORK FOR THE ABOVE QUESTION ABOVE THIS CELL\n",
    "# THIS UNALTERABLE CELL CONTAINS HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c71427c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "023e661d06327f7071013331ef569261",
     "grade": false,
     "grade_id": "cell-878793ee1cb75b9b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 4) Vectorize the Data\n",
    "\n",
    "In the cell below, vectorize the training and test datasets using the fitted count vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd25650",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T18:51:41.047346Z",
     "start_time": "2021-11-08T18:51:40.809618Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f2e04d2054ecf7d155d32628a722be6",
     "grade": false,
     "grade_id": "cell-2de1876d86b996ef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Replace None with appropriate code\n",
    "\n",
    "X_train_vectorized = None\n",
    "X_test_vectorized = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c99cdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T18:51:41.136271Z",
     "start_time": "2021-11-08T18:51:41.049426Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7dc770970b2f154ec6402d5b791f76ea",
     "grade": true,
     "grade_id": "cell-3d14b3e53ce6201a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.sparse.csr import csr_matrix\n",
    "assert type(X_train_vectorized) == csr_matrix\n",
    "assert type(X_test_vectorized) == csr_matrix\n",
    "# PUT ALL WORK FOR THE ABOVE QUESTION ABOVE THIS CELL\n",
    "# THIS UNALTERABLE CELL CONTAINS HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf2cff0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5bd87e1b2953c11fb75fdd2e1824bb9d",
     "grade": false,
     "grade_id": "cell-c7f79ea442cc186b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 5) Fit a Decision Tree Model\n",
    "\n",
    "In the cell below, \n",
    "\n",
    "- Create an instance of `sklearn`'s `DecisionTreeClassifier` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)), using default arguments, with the variable name `dt`\n",
    "- Fit the model to the vectorized training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de740888",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T18:51:42.154158Z",
     "start_time": "2021-11-08T18:51:41.138578Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10af0780ee69215d387a254834d5acaa",
     "grade": false,
     "grade_id": "cell-149edcbb04ffb6c8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Replace None with appropriate code\n",
    "\n",
    "# Import DecisionTreeClassifier\n",
    "None\n",
    "\n",
    "# Initialize `dt`\n",
    "dt = None\n",
    "\n",
    "# Fit the model to the training data\n",
    "None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70462da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T18:51:42.158746Z",
     "start_time": "2021-11-08T18:51:42.156340Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33eac0da92163d235fd1c364c91e21c4",
     "grade": true,
     "grade_id": "cell-88468f1c4fc90f0f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert dt\n",
    "# PUT ALL WORK FOR THE ABOVE QUESTION ABOVE THIS CELL\n",
    "# THIS UNALTERABLE CELL CONTAINS HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c388e3a2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f1e9a48f0fbf124feff21ec93cb51c01",
     "grade": false,
     "grade_id": "cell-cdaffa8177aaf22f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The following code will now evaluate our model on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a974edb4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "087d92cd51b6c7056dd9460227738131",
     "grade": false,
     "grade_id": "cell-1c19dcab44955d73",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "plot_confusion_matrix(dt, X_test_vectorized, y_test, ax=ax, cmap=\"cividis\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
